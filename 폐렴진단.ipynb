{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ovrkDJyMFeV47bXVejpywN78vHWFuRUq",
      "authorship_tag": "ABX9TyMuxZkzxYor75431q3fAoeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younguk072023/Pytorch_study/blob/main/%ED%8F%90%EB%A0%B4%EC%A7%84%EB%8B%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czaQFBst_bNX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 데이터 전처리 및 변환 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet 입력 크기로 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # 흑백(X-ray) 데이터 정규화\n",
        "])\n",
        "\n",
        "# Google Drive 마운트 및 데이터셋 경로 설정\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/MyDrive/딥러닝 논문_코드구현/chest_xray/chest_xray\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "\n",
        "# 데이터셋 로드 및 학습/검증/테스트 데이터 분할\n",
        "full_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# 데이터 로더 설정\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 클래스 확인\n",
        "print(\"Class labels:\", full_dataset.classes)  # ['NORMAL', 'PNEUMONIA']\n"
      ],
      "metadata": {
        "id": "sFZcAkFEAZc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구축 (ResNet101 사용)\n",
        "model = models.resnet101(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256, 1),  # 이진 분류 (정상, 폐렴)\n",
        "    nn.Sigmoid()  # Sigmoid로 확률값 출력\n",
        ")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "KqasL9J-AgKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.BCELoss()  # 이진 교차 엔트로피 손실\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 감소 스케줄러 설정\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n"
      ],
      "metadata": {
        "id": "Hg4Vu_v3AiPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping 클래스 정의\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, path='best_model.pth'):\n",
        "        \"\"\"\n",
        "        EarlyStopping 클래스는 모델이 더 이상 개선되지 않을 때 학습을 중단하도록 합니다.\n",
        "\n",
        "        :param patience: 개선이 없을 경우 기다리는 epoch 수\n",
        "        :param delta: 개선된 것으로 인정할 최소 변화량\n",
        "        :param path: 최적 모델을 저장할 경로\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.best_loss = np.inf\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), self.path)  # 최적 모델 저장\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            print(f\"🔹 EarlyStopping counter: {self.counter} / {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "# EarlyStopping 객체 생성\n",
        "early_stopping = EarlyStopping(patience=5, delta=0.001, path=\"best_resnet101.pth\")\n"
      ],
      "metadata": {
        "id": "ZyPfkt4tAkRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 함수\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, num_epochs=100):\n",
        "    \"\"\"\n",
        "    모델을 학습하고, 검증 데이터로 평가한 후 정확도와 손실을 기록합니다.\n",
        "\n",
        "    :param model: 학습할 모델\n",
        "    :param train_loader: 학습 데이터 로더\n",
        "    :param val_loader: 검증 데이터 로더\n",
        "    :param criterion: 손실 함수\n",
        "    :param optimizer: 옵티마이저\n",
        "    :param scheduler: 학습률 스케줄러\n",
        "    :param early_stopping: EarlyStopping 객체\n",
        "    :param num_epochs: 총 학습 epoch 수\n",
        "    :return: 학습 및 검증 정확도를 기록한 리스트\n",
        "    \"\"\"\n",
        "    train_acc_list, val_acc_list = [], []\n",
        "\n",
        "    # tqdm을 사용하여 학습 진행 상황을 시각적으로 표시\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\", ncols=100, leave=True):\n",
        "        model.train()\n",
        "        correct, total, running_loss = 0, 0, 0.0\n",
        "\n",
        "        # 학습 데이터 배치 처리\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        train_acc_list.append(train_acc)\n",
        "\n",
        "        # 검증 데이터 평가\n",
        "        model.eval()\n",
        "        correct, total, val_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        val_acc_list.append(val_acc)\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # 학습률 스케줄러 업데이트\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Early Stopping 체크\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early Stopping! 학습을 종료합니다.\")\n",
        "            break\n",
        "\n",
        "    return train_acc_list, val_acc_list\n"
      ],
      "metadata": {
        "id": "BMIBnF3sAn95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 함수\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"\n",
        "    테스트 데이터셋을 사용하여 모델을 평가하고 정확도를 출력합니다.\n",
        "\n",
        "    :param model: 평가할 모델\n",
        "    :param test_loader: 테스트 데이터 로더\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"테스트 정확도: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "d7Mlg056wlfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 시각화 함수\n",
        "def plot_accuracy(train_acc, val_acc):\n",
        "    \"\"\"\n",
        "    학습과 검증 정확도를 그래프로 시각화합니다.\n",
        "\n",
        "    :param train_acc: 학습 정확도 리스트\n",
        "    :param val_acc: 검증 정확도 리스트\n",
        "    \"\"\"\n",
        "    plt.plot(train_acc, label=\"Train Accuracy\")\n",
        "    plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Zms8t3O0wofr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 시각화 함수\n",
        "def plot_confusion_matrix(model, test_loader):\n",
        "    \"\"\"\n",
        "    테스트 데이터셋에 대한 혼동 행렬을 시각화합니다.\n",
        "\n",
        "    :param model: 평가할 모델\n",
        "    :param test_loader: 테스트 데이터 로더\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "R3eXU0eMwqdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 이미지 10개와 예측 라벨 출력 함수\n",
        "def show_random_images_with_predictions(model, test_loader):\n",
        "    \"\"\"\n",
        "    테스트 데이터에서 랜덤으로 10개의 이미지를 선택하고, 해당 예측 라벨을 함께 출력합니다.\n",
        "\n",
        "    :param model: 예측할 모델\n",
        "    :param test_loader: 테스트 데이터 로더\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    data_iter = iter(test_loader)\n",
        "\n",
        "    # 랜덤 샘플 10개\n",
        "    for _ in range(10):\n",
        "        inputs, labels = next(data_iter)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 예측\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "\n",
        "        # 이미지와 라벨 출력\n",
        "        for i in range(len(inputs)):\n",
        "            image = inputs[i].cpu().numpy().transpose((1, 2, 0))  # HWC 형식으로 변환\n",
        "            image = (image * 0.5) + 0.5  # 정규화 역변환\n",
        "            label = 'Pneumonia' if labels[i].item() == 1 else 'Normal'\n",
        "            pred = 'Pneumonia' if predicted[i].item() == 1 else 'Normal'\n",
        "\n",
        "            plt.imshow(image)\n",
        "            plt.title(f\"True: {label}, Pred: {pred}\")\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "DPi8YG1IwsZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 평가 시작\n",
        "train_acc, val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, num_epochs=30)\n",
        "evaluate_model(model, test_loader)\n",
        "plot_accuracy(train_acc, val_acc)\n",
        "plot_confusion_matrix(model, test_loader)\n",
        "show_random_images_with_predictions(model, test_loader)\n"
      ],
      "metadata": {
        "id": "eB42MwEcwtiW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}