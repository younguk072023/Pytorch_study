{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ovrkDJyMFeV47bXVejpywN78vHWFuRUq",
      "authorship_tag": "ABX9TyMuxZkzxYor75431q3fAoeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younguk072023/Pytorch_study/blob/main/%ED%8F%90%EB%A0%B4%EC%A7%84%EB%8B%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czaQFBst_bNX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜ ì„¤ì •\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # í‘ë°±(X-ray) ë°ì´í„° ì •ê·œí™”\n",
        "])\n",
        "\n",
        "# Google Drive ë§ˆìš´íŠ¸ ë° ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/MyDrive/ë”¥ëŸ¬ë‹ ë…¼ë¬¸_ì½”ë“œêµ¬í˜„/chest_xray/chest_xray\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë¡œë“œ ë° í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
        "full_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì„¤ì •\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# í´ë˜ìŠ¤ í™•ì¸\n",
        "print(\"Class labels:\", full_dataset.classes)  # ['NORMAL', 'PNEUMONIA']\n"
      ],
      "metadata": {
        "id": "sFZcAkFEAZc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ êµ¬ì¶• (ResNet101 ì‚¬ìš©)\n",
        "model = models.resnet101(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256, 1),  # ì´ì§„ ë¶„ë¥˜ (ì •ìƒ, íë ´)\n",
        "    nn.Sigmoid()  # Sigmoidë¡œ í™•ë¥ ê°’ ì¶œë ¥\n",
        ")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "KqasL9J-AgKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "criterion = nn.BCELoss()  # ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# í•™ìŠµë¥  ê°ì†Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n"
      ],
      "metadata": {
        "id": "Hg4Vu_v3AiPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping í´ë˜ìŠ¤ ì •ì˜\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, path='best_model.pth'):\n",
        "        \"\"\"\n",
        "        EarlyStopping í´ë˜ìŠ¤ëŠ” ëª¨ë¸ì´ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¤‘ë‹¨í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
        "\n",
        "        :param patience: ê°œì„ ì´ ì—†ì„ ê²½ìš° ê¸°ë‹¤ë¦¬ëŠ” epoch ìˆ˜\n",
        "        :param delta: ê°œì„ ëœ ê²ƒìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ë³€í™”ëŸ‰\n",
        "        :param path: ìµœì  ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.best_loss = np.inf\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), self.path)  # ìµœì  ëª¨ë¸ ì €ì¥\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            print(f\"ğŸ”¹ EarlyStopping counter: {self.counter} / {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "# EarlyStopping ê°ì²´ ìƒì„±\n",
        "early_stopping = EarlyStopping(patience=5, delta=0.001, path=\"best_resnet101.pth\")\n"
      ],
      "metadata": {
        "id": "ZyPfkt4tAkRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, num_epochs=100):\n",
        "    \"\"\"\n",
        "    ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€í•œ í›„ ì •í™•ë„ì™€ ì†ì‹¤ì„ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param model: í•™ìŠµí•  ëª¨ë¸\n",
        "    :param train_loader: í•™ìŠµ ë°ì´í„° ë¡œë”\n",
        "    :param val_loader: ê²€ì¦ ë°ì´í„° ë¡œë”\n",
        "    :param criterion: ì†ì‹¤ í•¨ìˆ˜\n",
        "    :param optimizer: ì˜µí‹°ë§ˆì´ì €\n",
        "    :param scheduler: í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
        "    :param early_stopping: EarlyStopping ê°ì²´\n",
        "    :param num_epochs: ì´ í•™ìŠµ epoch ìˆ˜\n",
        "    :return: í•™ìŠµ ë° ê²€ì¦ ì •í™•ë„ë¥¼ ê¸°ë¡í•œ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    train_acc_list, val_acc_list = [], []\n",
        "\n",
        "    # tqdmì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\", ncols=100, leave=True):\n",
        "        model.train()\n",
        "        correct, total, running_loss = 0, 0, 0.0\n",
        "\n",
        "        # í•™ìŠµ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        train_acc_list.append(train_acc)\n",
        "\n",
        "        # ê²€ì¦ ë°ì´í„° í‰ê°€\n",
        "        model.eval()\n",
        "        correct, total, val_loss = 0, 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        val_acc_list.append(val_acc)\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Early Stopping ì²´í¬\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early Stopping! í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "            break\n",
        "\n",
        "    return train_acc_list, val_acc_list\n"
      ],
      "metadata": {
        "id": "BMIBnF3sAn95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"\n",
        "    í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í‰ê°€í•˜ê³  ì •í™•ë„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param model: í‰ê°€í•  ëª¨ë¸\n",
        "    :param test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "d7Mlg056wlfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜\n",
        "def plot_accuracy(train_acc, val_acc):\n",
        "    \"\"\"\n",
        "    í•™ìŠµê³¼ ê²€ì¦ ì •í™•ë„ë¥¼ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param train_acc: í•™ìŠµ ì •í™•ë„ ë¦¬ìŠ¤íŠ¸\n",
        "    :param val_acc: ê²€ì¦ ì •í™•ë„ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    plt.plot(train_acc, label=\"Train Accuracy\")\n",
        "    plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Zms8t3O0wofr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í˜¼ë™ í–‰ë ¬ ì‹œê°í™” í•¨ìˆ˜\n",
        "def plot_confusion_matrix(model, test_loader):\n",
        "    \"\"\"\n",
        "    í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param model: í‰ê°€í•  ëª¨ë¸\n",
        "    :param test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "R3eXU0eMwqdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëœë¤ ì´ë¯¸ì§€ 10ê°œì™€ ì˜ˆì¸¡ ë¼ë²¨ ì¶œë ¥ í•¨ìˆ˜\n",
        "def show_random_images_with_predictions(model, test_loader):\n",
        "    \"\"\"\n",
        "    í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ëœë¤ìœ¼ë¡œ 10ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ê³ , í•´ë‹¹ ì˜ˆì¸¡ ë¼ë²¨ì„ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "    :param model: ì˜ˆì¸¡í•  ëª¨ë¸\n",
        "    :param test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    data_iter = iter(test_loader)\n",
        "\n",
        "    # ëœë¤ ìƒ˜í”Œ 10ê°œ\n",
        "    for _ in range(10):\n",
        "        inputs, labels = next(data_iter)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "\n",
        "        # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ì¶œë ¥\n",
        "        for i in range(len(inputs)):\n",
        "            image = inputs[i].cpu().numpy().transpose((1, 2, 0))  # HWC í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "            image = (image * 0.5) + 0.5  # ì •ê·œí™” ì—­ë³€í™˜\n",
        "            label = 'Pneumonia' if labels[i].item() == 1 else 'Normal'\n",
        "            pred = 'Pneumonia' if predicted[i].item() == 1 else 'Normal'\n",
        "\n",
        "            plt.imshow(image)\n",
        "            plt.title(f\"True: {label}, Pred: {pred}\")\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "DPi8YG1IwsZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì‹œì‘\n",
        "train_acc, val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, num_epochs=30)\n",
        "evaluate_model(model, test_loader)\n",
        "plot_accuracy(train_acc, val_acc)\n",
        "plot_confusion_matrix(model, test_loader)\n",
        "show_random_images_with_predictions(model, test_loader)\n"
      ],
      "metadata": {
        "id": "eB42MwEcwtiW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}