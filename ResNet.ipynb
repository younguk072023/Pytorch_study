{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNa8XhD+qHk4/a3VJ2GpOxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younguk072023/Pytorch_study/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB66gei_UlVU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/'딥러닝 논문_코드구현'/pcamv1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NL6widOIW7X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "src_dir = Path(\"/content/drive/MyDrive/딥러닝 논문_코드구현/pcamv1\")\n",
        "dst_dir = Path(\"pcam\")\n",
        "\n",
        "dst_dir.mkdir(exist_ok=True)\n",
        "\n",
        "for src in src_dir.iterdir():\n",
        "  if src.suffix == \".gz\":\n",
        "    with gzip.open(src, \"rb\") as f_in:\n",
        "      dst=dst_dir / src.stem\n",
        "      with open(dst, \"wb\")as f_out:\n",
        "        shutil.copyfileobj(f_in,f_out)\n",
        "\n",
        "  else:\n",
        "    dst=dst_dir/src.name\n",
        "    shutil.copy2(src,dst)"
      ],
      "metadata": {
        "id": "1FrPX0vNZ09_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "trn_transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.RandomResizedCrop(size=(96,96),antialias=True),\n",
        "    v2.RandomHorizontalFlip(p=0.5),#이미지 50%확률로 수평 반전\n",
        "    v2.RandomVerticalFlip(p=0.5),#이미지가 50% 확률로 수직 반전\n",
        "    v2.ToDtype(torch.float32, scale=True),#픽셀값 0에서1 범위로 정규\n",
        "    v2.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),#이미지넷 정규화 기준\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "test_transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32,scale=True),\n",
        "    v2.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "hEIkXCkPvx6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import PCAM\n",
        "trn_dataset = PCAM(\".\", split=\"train\",transform=trn_transforms)\n",
        "test_dataset = PCAM(\".\",split=\"test\", transform=test_transforms)"
      ],
      "metadata": {
        "id": "j7afLhWwyYeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(inp):\n",
        "  \"\"\"Display image for Tensor.\"\"\"\n",
        "  inp=inp.numpy().transpose((1,2,0))#채널,높이,너비는 기본적인 파이토치, matplot에서는 높이, 너비, 채널 순\n",
        "  mean=np.array([0.485,0.456,0.406])\n",
        "  std=np.array([0.229,0.224,0.225])\n",
        "  inp=np.clip(inp,0,1)\n",
        "  plt.imshow(inp)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UVvo42-WyYxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5개의 이미지를 가로로 표시\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 3))  # 1행 5열로 subplot 생성\n",
        "\n",
        "for i in range(5):\n",
        "    axes[i].imshow(trn_dataset[i][0].numpy().transpose((1, 2, 0)))\n",
        "    axes[i].axis('off')  # 축 없애기\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fk72O8mD1SpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "trn_loader=torch.utils.data.DataLoader(trn_dataset,batch_size=64,shuffle=True, num_workers=2)\n",
        "tst_loader=torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=False,num_workers=2)\n"
      ],
      "metadata": {
        "id": "RNN1q9iB2mf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "JCHOmfjW3Jls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, criterion, optimizer, trn_loader, test_loader, num_epochs=25):\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    trn_loss=0.0\n",
        "    trn_corrects=0\n",
        "    for inputs, labels in tqdm(trn_loader):\n",
        "      inputs=inputs.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs,1)\n",
        "      loss=criterion(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      trn_loss+= loss.titem()*inputs.size(0)\n",
        "      trn_corrects+=torch.sum(preds==labels.data)\n",
        "\n",
        "    trn_epoch_loss= trn_loss/len(trn_loader.dataset)\n",
        "    trn_epoch_acc=trn_corrects.double()/len(trn_loader.dataset)\n",
        "    print(f\"[Train] Loss : {trn_epoch_loss:.4f} Acc:{trn_epoch_acc:.4f}\")\n",
        "\n",
        "    with torch.no.grad():\n",
        "      model.eval()\n",
        "      test_loss=0.0\n",
        "      test_corrects=0\n",
        "      for inputs,labels in tqdm(test_loader):\n",
        "        inputs=inputs.to(device)\n",
        "        labels=labels.to(device)\n",
        "\n",
        "        outputs=model(inputs)\n",
        "        _,preds=torch.max(outputs,1)\n",
        "        loss=criterion(outputs,labels)\n",
        "\n",
        "        test_loss+=loss.item()*inputs.size(0)\n",
        "        test_corrects+=torch.sum(preds==labels.data)\n",
        "\n",
        "      test_epoch_loss=test_loss / len(test_loader.dataset)\n",
        "      test_epoch_acc = test_corrects.double()/ len(test_loader.dataset)\n",
        "      print(f\"[Test] Loss: {test_epoch_loss:.4f} Acc: {test_epoch_acc:,4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5g9kXLAK3Y0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "model=model.to(device)"
      ],
      "metadata": {
        "id": "JNWVxuzz3Y7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ftrs=model.fc.in_features\n",
        "model.fc=nn.Linear(num_ftrs,2)"
      ],
      "metadata": {
        "id": "naztFvNw6uP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "jIHIZ5is67fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, criterion, optimizer, trn_loader, tst_loader, num_epochs=10)"
      ],
      "metadata": {
        "id": "lT7lgDng7D9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/cotent/drive/MyDrive/model_pcam.pth\")\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model_pcam.pth\"))"
      ],
      "metadata": {
        "id": "QcHxFPjO6ufv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "  model.eval()\n",
        "  images_so_far=0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (inouts,labels) in enumerate(tst_loader):\n",
        "      inputs= inputs.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "      outputs=model(inputs)\n",
        "      _,preds = torch.max(outputs,1)\n",
        "\n",
        "      for j in range(inputs.size()[0]):\n",
        "        images_so_far+=1\n",
        "        imshow(inputs.cpu()[j])\n",
        "        print(f'predicted:{preds[j]}')\n",
        "        print(f\"label:{labels[j]}\")"
      ],
      "metadata": {
        "id": "ZIBi-kr48HQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}