{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP90/wb455fdk0DkX/dnyQ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younguk072023/Pytorch_study/blob/main/Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyXAKtPcp9IP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "JJQAl9zFqSW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로딩\n",
        "\n",
        "def get_train_valid_loader(data_dir, batch_size, augment, random_seed, valid_size=0.1, shuffle=True):\n",
        "  normalize = transforms.Normalize (\n",
        "      mean = [0.4914, 0.4822, 0.4465,], #RGB채널별 평균값\n",
        "      std = [0.2023,0.1994,0.2010],#RGB 채널별 표준 편차\n",
        "  )\n",
        "\n",
        "#define transforms\n",
        "  valid_transform = transforms.Compose([\n",
        "      transforms.Resize((227,227)),\n",
        "      transforms.ToTensor(),\n",
        "      normalize,\n",
        "  ])\n",
        "\n",
        "  if augment:\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        normalize,\n",
        "\n",
        "    ])\n",
        "\n",
        "  else:\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((227,227)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "\n",
        "      ])\n",
        "#load the dataset\n",
        "  train_dataset = datasets.CIFAR10(\n",
        "      root=data_dir, train=True,\n",
        "      download=True, transform=train_transform,\n",
        "      )\n",
        "\n",
        "  valid_dataset = datasets.CIFAR10(\n",
        "      root=data_dir, train=True,\n",
        "      download=True, transform=valid_transform,\n",
        "\n",
        "  )\n",
        "\n",
        "  num_train = len(train_dataset)\n",
        "  indices = list(range(num_train))\n",
        "  split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "  if shuffle:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "  train_idx, valid_idx = indices[split:], indices[:split]\n",
        "  train_sampler = SubsetRandomSampler(train_idx)\n",
        "  valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset, batch_size=batch_size, sampler=train_sampler\n",
        "  )\n",
        "\n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset, batch_size=batch_size, sampler=valid_sampler\n",
        "  )\n",
        "\n",
        "  return(train_loader, valid_loader)\n",
        "\n",
        "def get_test_loader(data_dir, batch_size, shuffler=True):\n",
        "  normalize = transforms.Normalize(\n",
        "      mean=[0.485, 0.456,0.406],\n",
        "      std=[0.229,0.224,0.225],\n",
        "  )\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((227,227)),\n",
        "      transforms.ToTensor(),\n",
        "      normalize,\n",
        "  ])\n",
        "\n",
        "  dataset = datasets.CIFAR10(\n",
        "      root=data_dir, train=False,\n",
        "      download=True, transform=transform,\n",
        "  )\n",
        "\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "      dataset, batch_size=batch_size, shuffle = True\n",
        "  )\n",
        "\n",
        "  return data_loader\n",
        "\n",
        "train_loader, valid_loader = get_train_valid_loader(data_dir = './data',  batch_size = 64,\n",
        "                       augment = False,     random_seed = 1)\n",
        "\n",
        "test_loader = get_test_loader(data_dir = './data',\n",
        "                              batch_size = 64)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "B8D412n5qZEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(Self, num_classes=10):#출력 클래스 개수 정해줌 10\n",
        "    super(AlexNet, Self).__init__()\n",
        "    Self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(3,96,kernel_size=11, stride=4,padding=0),#입력채널 3, 출력채널 96, 필터크기 11x1\n",
        "        nn.BatchNorm2d(96),#배치정규화 정규화하여 학습을 안정하는 역할 채널 수 96\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "    Self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(96,256,kernel_size=5, stride=1, padding=2), #출력값 계산은\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "    Self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(256,384,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(384),\n",
        "        nn.ReLU())\n",
        "    Self.layer4=nn.Sequential(\n",
        "        nn.Conv2d(384,384,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(384),\n",
        "        nn.ReLU())\n",
        "    Self.layer5=nn.Sequential(\n",
        "        nn.Conv2d(384, 256, kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3,stride=2))\n",
        "    Self.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(9216,4096),\n",
        "        nn.ReLU())\n",
        "    Self.fc1=nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU())\n",
        "    Self.fc2=nn.Sequential(\n",
        "        nn.Linear(4096,num_classes))\n",
        "\n",
        "  def forward(self,x):\n",
        "      out = self.layer1(x)\n",
        "      out = self.layer2(out)\n",
        "      out = self.layer3(out)\n",
        "      out = self.layer4(out)\n",
        "      out = self.layer5(out)\n",
        "      out = out.reshape(out.size(0), -1)\n",
        "      out = self.fc(out)\n",
        "      out = self.fc1(out)\n",
        "      out = self.fc2(out)\n",
        "      return out\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ZX8RJzlMWa8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=10\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate=0.005\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005,momentum=0.9)\n",
        "\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "JkbpwqYkIoZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images, labels) in enumerate(train_loader): #enumerate (인덱스, 값)\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print('Epoch [{}/{}], step[{}/{}], Loss : {:.4f}'.format(epoch+1,num_epochs,i+1,total_step,loss.item()))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct=0\n",
        "    total=0\n",
        "    for images, labels in valid_loader:\n",
        "      images=images.to(device)\n",
        "      labels=labels.to(device)\n",
        "      outputs=model(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total +=labels.size(0)\n",
        "      correct+=(predicted==labels).sum().item()\n",
        "      del images, labels, outputs\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      correct=0\n",
        "      total=0\n",
        "      for images, labels in test_loader:\n",
        "        images=images.to(device)\n",
        "        labels=labels.to(device)\n",
        "        outputs=model(images)\n",
        "        _, predicted = torch.max(outputs.data,1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=(predicted==labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "      print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uefZzQpQJWVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdcnf4mZPPoF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}